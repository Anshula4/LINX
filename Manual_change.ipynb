{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install and Import Libraries"
      ],
      "metadata": {
        "id": "_b3GYIIViDvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pandas openpyxl xlsxwriter -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "KRVUzjsiMm0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Helper Functions"
      ],
      "metadata": {
        "id": "JwVeUcQgiWEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to upload and read an Excel file\n",
        "def upload_excel_file(file_type):\n",
        "    print(f\"\\nPlease upload your {file_type} Excel file:\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        try:\n",
        "            df = pd.read_excel(io.BytesIO(uploaded[filename]))\n",
        "            return df, filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "# Function to preview dataframe\n",
        "def preview_data(df, title, max_rows=3):\n",
        "    if df is not None:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"{title} Preview\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "        print(f\"\\nFirst {max_rows} rows:\")\n",
        "        print(df.head(max_rows).to_string())\n",
        "\n",
        "# Function to save and download DataFrame\n",
        "def save_and_download_file(df, filename):\n",
        "    try:\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "        print(f\"\\nSaving and downloading {filename}...\")\n",
        "        files.download(filename)\n",
        "        print(f\"Download initiated for {filename}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving/downloading file: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "LLu3hs8TMm2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Language Lookup Table"
      ],
      "metadata": {
        "id": "YSd14nPWiaJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_language_lookup():\n",
        "    lookup_data = [\n",
        "        ['AE', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['AO', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['AR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['AT', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['AU', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['AZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['BA', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],\n",
        "        ['BD', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['BE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['BG', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],\n",
        "        ['BO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['BR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['BW', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['BY', 'English-Russia', 'SDWN EngRus'],\n",
        "        ['CA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['CH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['CI', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['CL', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['CM', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['CN', 'English-Chinese', 'SDWN EnglishChinese'],\n",
        "        ['CO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['CR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['CX', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],\n",
        "        ['CY', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],\n",
        "        ['CZ', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],\n",
        "        ['DE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['DK', 'EN-DA-SV-NN', 'SDWN ENDASVNN'],\n",
        "        ['DO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['DU', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['DX', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['DZ', 'ENGLISH-ARABIC', 'SDWN EngArabic Codal'],\n",
        "        ['EC', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['EE', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],\n",
        "        ['EG', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['ES', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['FI', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],\n",
        "        ['FR', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['GB', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['GE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['GH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['GP', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['GR', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],\n",
        "        ['HK', 'English-Chinese', 'SDWN EnglishChinese'],\n",
        "        ['HR', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],\n",
        "        ['HU', 'English-Hungary (Printec)', 'SDWN EngHungary'],\n",
        "        ['ID', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['IE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['IL', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['IN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['IQ', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['IR', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['IT', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],\n",
        "        ['JO', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['JP', 'English-Japanese', 'SDWN EngJapan'],\n",
        "        ['KE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['KG', 'English-Russia', 'SDWN EngRus'],\n",
        "        ['KR', 'English-Korean', 'SDWN EngKorean'],\n",
        "        ['KW', 'English-Arabic', 'SDWN EngArabic'],\n",
        "        ['KZ', 'English-Russia', 'SDWN EngRus'],\n",
        "        ['LB', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['LK', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['LT', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],\n",
        "        ['LV', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],\n",
        "        ['LY', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['MA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['MC', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['MD', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['MU', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['MX', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['MY', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['NC', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['NG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['NL', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['NO', 'EN-DA-SV-NL', 'SDWN ENDASVNL'],\n",
        "        ['NP', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['NZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['OM', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['PE', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['PH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['PK', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['PL', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],\n",
        "        ['PR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['PT', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['PY', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['QA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['RO', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],\n",
        "        ['RS', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],\n",
        "        ['RU', 'English-Russia', 'SDWN EngRus'],\n",
        "        ['SA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['SD', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['SE', 'EN-DA-SV-NL', 'SDWN ENDASVNL'],\n",
        "        ['SG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['SI', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],\n",
        "        ['SK', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],\n",
        "        ['SN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['SV', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['SY', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['TG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['TH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['TJ', 'English-Russia', 'SDWN EngRus'],\n",
        "        ['TN', 'ENGLISH-ARABIC', 'SDWN EngArabic'],\n",
        "        ['TR', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],\n",
        "        ['TT', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['TW', 'English-ChineseT', 'SDWN EnglishChinaT'],\n",
        "        ['UA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['UG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['US', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['UZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['VE', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],\n",
        "        ['VN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['XS', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['XX', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['ZA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['ZM', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],\n",
        "        ['ZW', 'EN-FR-DE-NL', 'SDWN ENFRDENL']\n",
        "    ]\n",
        "    lang_lookup_df = pd.DataFrame(lookup_data, columns=['COUNTRY_CODE', 'NEW_LANG', 'SDWN'])\n",
        "    return lang_lookup_df\n",
        "\n",
        "language_lookup = create_language_lookup()\n",
        "print(\"lang_lookup_df sample:\", language_lookup.head().to_string())"
      ],
      "metadata": {
        "id": "OVRHzcmPMm5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload and Process SOH Bottles Data"
      ],
      "metadata": {
        "id": "qLoRIuFJidzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSTEP 1: Upload SOH Bottles Excel File\")\n",
        "soh_data, soh_filename = upload_excel_file(\"SOH Bottles Sheet\")\n",
        "if soh_data is not None:\n",
        "    item_col = next((col for col in soh_data.columns if 'item' in str(col).lower()), None)\n",
        "    if item_col:\n",
        "        soh_data = soh_data[soh_data[item_col].notna() & (soh_data[item_col].astype(str).str.strip() != '')]\n",
        "    preview_data(soh_data, \"SOH Bottles Data\")"
      ],
      "metadata": {
        "id": "7SeR95AMMm9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload and Process Export Sheet"
      ],
      "metadata": {
        "id": "_36Q1gAwinuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSTEP 2: Upload and Convert Export Sheet to Order Format\")\n",
        "export_data, export_filename = upload_excel_file(\"Export Sheet\")\n",
        "if export_data is not None:\n",
        "    print(f\"Initial data shape: {export_data.shape[0]} rows × {export_data.shape[1]} columns\")\n",
        "\n",
        "    # Filter out Released status\n",
        "    status_column = next((col for col in export_data.columns if 'status' in str(col).lower()), export_data.columns[17] if export_data.shape[1] >= 18 else None)\n",
        "    if status_column:\n",
        "        print(f\"\\nFiltering out orders with Status = 'Released' from column: '{status_column}'\")\n",
        "        before_filter = len(export_data)\n",
        "        export_data = export_data[~export_data[status_column].astype(str).str.upper().str.strip().eq('RELEASED')]\n",
        "        print(f\"Removed {before_filter - len(export_data)} orders with 'Released' status\")\n",
        "    else:\n",
        "        print(\"WARNING: Status column not found\")\n",
        "\n",
        "    # Filter out batch-assigned orders\n",
        "    batch_columns = [col for col in export_data.columns if any(kw in str(col).lower() for kw in ['batch', 'lot', 'production order', 'work order'])]\n",
        "    print(f\"\\nFound potential batch columns: {batch_columns}\")\n",
        "    if batch_columns:\n",
        "        before_batch_filter = len(export_data)\n",
        "        batch_filter_mask = pd.Series(False, index=export_data.index)\n",
        "        for batch_col in batch_columns:\n",
        "            has_batch = (\n",
        "                export_data[batch_col].notna() &\n",
        "                (export_data[batch_col].astype(str).str.strip() != '') &\n",
        "                (export_data[batch_col].astype(str).str.strip().str.upper() != 'NAN')\n",
        "            )\n",
        "            batch_filter_mask |= has_batch\n",
        "            print(f\"  {batch_col}: {has_batch.sum()} orders have batch numbers assigned\")\n",
        "        export_data = export_data[~batch_filter_mask]\n",
        "        print(f\"Removed {before_batch_filter - len(export_data)} orders with batch numbers assigned\")\n",
        "    else:\n",
        "        print(\"No batch-related columns found\")\n",
        "\n",
        "    # Filter non-empty sales orders\n",
        "    sales_col = next((col for col in export_data.columns if 'sales order' in str(col).lower()), None)\n",
        "    if sales_col:\n",
        "        before_sales_filter = len(export_data)\n",
        "        export_data = export_data[export_data[sales_col].notna() & (export_data[sales_col].astype(str).str.strip() != '')]\n",
        "        print(f\"Removed {before_sales_filter - len(export_data)} empty sales orders\")\n",
        "    print(f\"\\nFinal filtered data shape: {export_data.shape[0]} rows × {export_data.shape[1]} columns\")\n",
        "\n",
        "    # Convert to order format\n",
        "    order_data = pd.DataFrame()\n",
        "    column_mappings = {\n",
        "        'Order Number': ['sales order'],\n",
        "        'Customer ID': ['ship to country'],\n",
        "        'SKU Code': ['item'],\n",
        "        'Original Order Quantity': ['quantity'],\n",
        "        'Reserved Quantity': ['reserved quantity'],\n",
        "        'Order Date (dd/mm/yyyy)': ['upload date', 'batch start date', 'order date', 'date'],\n",
        "        'Requested Delivery Date (dd/mm/yyyy)': ['scheduled ship date', 'due date', 'schedule ship date'],\n",
        "        'Priority': ['language'],\n",
        "        'Order Type': ['delivery method'],\n",
        "        'Agent Name': ['linx agent', 'on hold', 'agent']\n",
        "    }\n",
        "    for target_col, search_terms in column_mappings.items():\n",
        "        source_col = next((col for col in export_data.columns if any(term.lower() in str(col).lower() for term in search_terms)), None)\n",
        "        if source_col:\n",
        "            order_data[target_col] = export_data[source_col]\n",
        "            print(f\"Mapped '{target_col}' to source column: '{source_col}'\")\n",
        "        else:\n",
        "            if target_col == 'Agent Name':\n",
        "                order_data[target_col] = 'Linx Agent'\n",
        "            elif target_col == 'Order Date (dd/mm/yyyy)':\n",
        "                order_data[target_col] = datetime.now().strftime('%d/%m/%Y')\n",
        "            elif target_col == 'Reserved Quantity':\n",
        "                order_data[target_col] = 0\n",
        "                print(f\"WARNING: No 'Reserved Quantity' column found. Defaulting to 0.\")\n",
        "            else:\n",
        "                order_data[target_col] = ''\n",
        "\n",
        "    # Set Order Quantity and add other columns\n",
        "    order_data['Original Order Quantity'] = pd.to_numeric(order_data['Original Order Quantity'], errors='coerce').fillna(0)\n",
        "    order_data['Reserved Quantity'] = pd.to_numeric(order_data['Reserved Quantity'], errors='coerce').fillna(0)\n",
        "    order_data['Order Quantity'] = order_data['Reserved Quantity']\n",
        "    order_data['Location ID'] = 'WH_Default'\n",
        "\n",
        "    # Split Order Number into Order Number and Line Number\n",
        "    if 'Order Number' in order_data.columns:\n",
        "        order_line_data = order_data['Order Number'].apply(lambda x: ('LI' + str(x).split('/')[0], str(x).split('/')[1]) if '/' in str(x) else ('LI' + str(x), '1'))\n",
        "        order_data['Order Number'] = [x[0] for x in order_line_data]\n",
        "        order_data['Line Number'] = [x[1] for x in order_line_data]\n",
        "    else:\n",
        "        order_data['Line Number'] = range(1, len(export_data) + 1)\n",
        "\n",
        "    # Format dates\n",
        "    for date_col in ['Order Date (dd/mm/yyyy)', 'Requested Delivery Date (dd/mm/yyyy)']:\n",
        "        if date_col in order_data.columns:\n",
        "            order_data[date_col] = pd.to_datetime(order_data[date_col], errors='coerce').dt.strftime('%d/%m/%Y')\n",
        "\n",
        "    # Ensure required columns\n",
        "    required_columns = [\n",
        "        'Order Number', 'Line Number', 'Location ID', 'Customer ID', 'SKU Code',\n",
        "        'Original Order Quantity', 'Order Quantity', 'Order Date (dd/mm/yyyy)',\n",
        "        'Requested Delivery Date (dd/mm/yyyy)', 'Priority', 'Order Type', 'Agent Name'\n",
        "    ]\n",
        "    for col in required_columns:\n",
        "        if col not in order_data.columns:\n",
        "            order_data[col] = '1' if col == 'Line Number' else 'WH_Default' if col == 'Location ID' else 0 if col == 'Order Quantity' else ''\n",
        "    order_data = order_data[required_columns]\n",
        "\n",
        "    print(\"order_data Customer IDs sample:\", order_data['Customer ID'].head(10).to_string())\n",
        "    preview_data(order_data, \"Converted Order Data (Open Orders Only)\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "FjLZvZkidIRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert SOH Bottles to Inventory Format"
      ],
      "metadata": {
        "id": "mkUjwfFuitY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSTEP 3: Convert SOH Bottles Sheet to Inventory Format\")\n",
        "if soh_data is not None:\n",
        "    inventory_data = pd.DataFrame()\n",
        "    soh_mappings = {\n",
        "        'SKU Code': ['item', 'sku'],\n",
        "        'On Hand Inventory': ['available to reserve', 'available'],\n",
        "        'Reordered Quantity': ['total quantity', 'onhand', 'stock', 'quantity'],\n",
        "        'Locator': ['locator']\n",
        "    }\n",
        "    for target_col, search_terms in soh_mappings.items():\n",
        "        source_col = next((col for col in soh_data.columns if any(term.lower() in str(col).lower() for term in search_terms)), None)\n",
        "        if source_col:\n",
        "            inventory_data[target_col] = soh_data[source_col]\n",
        "        else:\n",
        "            inventory_data[target_col] = 0 if 'quantity' in target_col.lower() or 'inventory' in target_col.lower() else ''\n",
        "\n",
        "    # Exclude specific locators and add Location ID\n",
        "    if 'Locator' in inventory_data.columns:\n",
        "        exclude_mask = inventory_data['Locator'].astype(str).str.strip().str.upper() == '8900MAIN'\n",
        "        inventory_data = inventory_data[~exclude_mask].copy()\n",
        "        inventory_data['Location ID'] = inventory_data['Locator']\n",
        "    else:\n",
        "        inventory_data['Location ID'] = ''\n",
        "\n",
        "    # Add timestamp and aggregate\n",
        "    current_time = datetime.now().strftime('%d-%m-%Y %H:%M:%S')\n",
        "    inventory_data['Date and Time (DD-MM-YYYY HH:MM:SS)'] = current_time\n",
        "    inventory_data['On Hand Inventory'] = pd.to_numeric(inventory_data['On Hand Inventory'], errors='coerce').fillna(0)\n",
        "    inventory_data['Reordered Quantity'] = pd.to_numeric(inventory_data['Reordered Quantity'], errors='coerce').fillna(0)\n",
        "    inventory_data = inventory_data.groupby(['SKU Code', 'Location ID', 'Date and Time (DD-MM-YYYY HH:MM:SS)'], as_index=False).agg({\n",
        "        'On Hand Inventory': 'sum',\n",
        "        'Reordered Quantity': 'sum'\n",
        "    })\n",
        "\n",
        "    # Create copy with locator for later use\n",
        "    inventory_data_with_locator = inventory_data.copy()\n",
        "    inventory_data_with_locator['Locator'] = inventory_data_with_locator['Location ID']\n",
        "\n",
        "    # Select required columns\n",
        "    required_inventory_columns = [\n",
        "        'Location ID', 'SKU Code', 'On Hand Inventory', 'Reordered Quantity',\n",
        "        'Date and Time (DD-MM-YYYY HH:MM:SS)'\n",
        "    ]\n",
        "    inventory_data = inventory_data[required_inventory_columns]\n",
        "\n",
        "    preview_data(inventory_data, \"Converted Inventory Data\")\n",
        "else:\n",
        "    inventory_data = None\n",
        "    inventory_data_with_locator = None"
      ],
      "metadata": {
        "id": "pCXx7Ix5dIUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate New Lang Label and Stock"
      ],
      "metadata": {
        "id": "tWTzE9cFixiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_new_lang_label_and_stock(order_df, inventory_with_locator_df, lang_lookup_df):\n",
        "    result_df = order_df.copy()\n",
        "    if inventory_with_locator_df is None or lang_lookup_df is None:\n",
        "        print(\"WARNING: inventory_with_locator_df or lang_lookup_df is None. Setting SOH NEW LANG STOCK to 0.\")\n",
        "        result_df['ITEM New LANG LABEL'] = result_df['SKU Code']\n",
        "        result_df['SOH NEW LANG STOCK'] = 0\n",
        "        return result_df\n",
        "\n",
        "    def calculate_lang_info_for_item(row):\n",
        "        sku_code = str(row.get('SKU Code', '')).strip()\n",
        "        country = str(row.get('Customer ID', '')).strip().upper()\n",
        "        print(f\"Processing row: SKU={sku_code}, Raw Customer ID={row.get('Customer ID', '')}, Processed Country={country}\")\n",
        "        new_lang_label = sku_code\n",
        "        soh_new_lang_stock = 0\n",
        "\n",
        "        if pd.isna(sku_code) or sku_code == '' or pd.isna(country) or country == '':\n",
        "            print(f\"Skipping row: SKU={sku_code}, Country={country} (empty or invalid)\")\n",
        "            return new_lang_label, soh_new_lang_stock\n",
        "\n",
        "        country_match = lang_lookup_df[lang_lookup_df['COUNTRY_CODE'].str.upper() == country]\n",
        "        if len(country_match) == 0:\n",
        "            print(f\"No country match found for Customer ID: {country}, using default EN-FR-DE-NL\")\n",
        "            new_lang = 'EN-FR-DE-NL'  # Default language as fallback\n",
        "        else:\n",
        "            new_lang = country_match.iloc[0]['NEW_LANG']\n",
        "        new_lang_label = f\"{sku_code}{new_lang}\"\n",
        "        search_key = f\"{sku_code}{new_lang}\"\n",
        "\n",
        "        print(f\"Searching for SKU={sku_code}, Country={country}, Search Key={search_key}\")\n",
        "\n",
        "        matching_soh = inventory_with_locator_df[\n",
        "            (inventory_with_locator_df['SKU Code'].astype(str).str.strip() +\n",
        "             inventory_with_locator_df['Locator'].astype(str).str.strip()).str.upper() == search_key.upper()\n",
        "        ]\n",
        "        if len(matching_soh) > 0:\n",
        "            soh_new_lang_stock = pd.to_numeric(matching_soh['On Hand Inventory'], errors='coerce').fillna(0).sum()\n",
        "            print(f\"Match found (SKU+Locator): {search_key}, Stock={soh_new_lang_stock}\")\n",
        "        else:\n",
        "            matching_soh_direct = inventory_with_locator_df[\n",
        "                inventory_with_locator_df['SKU Code'].astype(str).str.strip().str.upper() == search_key.upper()\n",
        "            ]\n",
        "            if len(matching_soh_direct) > 0:\n",
        "                soh_new_lang_stock = pd.to_numeric(matching_soh_direct['On Hand Inventory'], errors='coerce').fillna(0).sum()\n",
        "                print(f\"Match found (SKU direct): {search_key}, Stock={soh_new_lang_stock}\")\n",
        "            else:\n",
        "                base_sku_match = inventory_with_locator_df[\n",
        "                    inventory_with_locator_df['SKU Code'].astype(str).str.strip().str.upper() == sku_code.upper()\n",
        "                ]\n",
        "                if len(base_sku_match) > 0:\n",
        "                    soh_new_lang_stock = pd.to_numeric(base_sku_match['On Hand Inventory'], errors='coerce').fillna(0).sum()\n",
        "                    print(f\"Using base SKU {sku_code}, Stock={soh_new_lang_stock}\")\n",
        "                else:\n",
        "                    print(f\"No match found for {search_key} or base SKU {sku_code}\")\n",
        "\n",
        "        return new_lang_label, soh_new_lang_stock\n",
        "\n",
        "    lang_results = result_df.apply(calculate_lang_info_for_item, axis=1, result_type='expand')\n",
        "    result_df['ITEM New LANG LABEL'] = lang_results[0]\n",
        "    result_df['SOH NEW LANG STOCK'] = lang_results[1]\n",
        "    return result_df\n",
        "\n",
        "print(\"\\nSTEP 4: Calculate New Lang Label and Stock\")\n",
        "if order_data is not None and inventory_data is not None and language_lookup is not None:\n",
        "    order_data = calculate_new_lang_label_and_stock(order_data, inventory_data_with_locator, language_lookup)\n",
        "    preview_data(order_data, \"Order Data with New Lang Label and Stock\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "CGHeNrB4dIXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Qty Outstanding"
      ],
      "metadata": {
        "id": "cvN3jBbSi1g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_qty_outstanding(order_df):\n",
        "    result_df = order_df.copy()\n",
        "    original_qty = pd.to_numeric(result_df['Original Order Quantity'], errors='coerce').fillna(0)\n",
        "    reserved_qty = pd.to_numeric(result_df['Order Quantity'], errors='coerce').fillna(0)\n",
        "    result_df['Qty Outstanding'] = (original_qty - reserved_qty).clip(lower=0)\n",
        "    return result_df\n",
        "\n",
        "print(\"\\nSTEP 5: Calculate Qty Outstanding\")\n",
        "if order_data is not None:\n",
        "    order_data = calculate_qty_outstanding(order_data)\n",
        "    preview_data(order_data, \"Order Data with Qty Outstanding\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "bSPk3CHzdIa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Available CAPS"
      ],
      "metadata": {
        "id": "_M1P8Tqui6w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_available_caps(order_df, inventory_df):\n",
        "    result_df = order_df.copy()\n",
        "    if inventory_df is None:\n",
        "        result_df['AVAILABLE CAPS'] = 0\n",
        "        return result_df\n",
        "\n",
        "    def calculate_caps_for_item(item_code):\n",
        "        if pd.isna(item_code) or str(item_code).strip() == '':\n",
        "            return 0\n",
        "        item_str = str(item_code).strip()\n",
        "        if len(item_str) >= 7:\n",
        "            mid_substring = item_str[2:7]\n",
        "            search_pattern = f\"AS{mid_substring}\"\n",
        "            matching_items = inventory_df[\n",
        "                inventory_df['SKU Code'].astype(str).str.contains(search_pattern, case=False, na=False, regex=False)\n",
        "            ]\n",
        "            if len(matching_items) > 0:\n",
        "                return pd.to_numeric(matching_items['On Hand Inventory'], errors='coerce').fillna(0).sum()\n",
        "        return 0\n",
        "\n",
        "    result_df['AVAILABLE CAPS'] = result_df['SKU Code'].apply(calculate_caps_for_item)\n",
        "    return result_df\n",
        "\n",
        "print(\"\\nSTEP 6: Calculate Available CAPS\")\n",
        "if order_data is not None and inventory_data is not None:\n",
        "    order_data = calculate_available_caps(order_data, inventory_data)\n",
        "    preview_data(order_data, \"Order Data with Available CAPS\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "WjESeSwUdIeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate 5 LANG Box Stock Item"
      ],
      "metadata": {
        "id": "PdRZgyx2i_NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_5_lang_box_stock(order_df, inventory_df):\n",
        "    result_df = order_df.copy()\n",
        "    if inventory_df is None:\n",
        "        result_df['5 LANG Box Stock item (Y/N)'] = 'N'\n",
        "        return result_df\n",
        "\n",
        "    def calculate_lang_box_for_item(sku_code):\n",
        "        if pd.isna(sku_code) or str(sku_code).strip() == '':\n",
        "            return 'N'\n",
        "        sku_str = str(sku_code).strip().upper()\n",
        "        matching_rows = inventory_df[\n",
        "            inventory_df['SKU Code'].astype(str).str.strip().str.upper() == sku_str\n",
        "        ]\n",
        "        if len(matching_rows) > 0:\n",
        "            soh_stock = pd.to_numeric(matching_rows['On Hand Inventory'], errors='coerce').fillna(0).sum()\n",
        "            return 'Y' if soh_stock > 0 else 'N'\n",
        "        return 'N'\n",
        "\n",
        "    result_df['5 LANG Box Stock item (Y/N)'] = result_df['SKU Code'].apply(calculate_lang_box_for_item)\n",
        "    return result_df\n",
        "\n",
        "print(\"\\nSTEP 7: Calculate 5 LANG Box Stock Item (Y/N)\")\n",
        "if order_data is not None and inventory_data is not None:\n",
        "    order_data = calculate_5_lang_box_stock(order_data, inventory_data)\n",
        "    preview_data(order_data, \"Order Data with 5 LANG Box Stock\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "H8iSqyzKMnAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate 5LL Pick Rule"
      ],
      "metadata": {
        "id": "jMhAYFJejDIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_5LL_pick_rule(order_df):\n",
        "    result_df = order_df.copy()\n",
        "    exclusion_skus = {\n",
        "        'FAC1248/5L', 'FAC1058/5L', 'FAC1079/5L', 'FAC1039/5L', 'FAC1405/5L',\n",
        "        'FAC1404/5L', 'FAC1406/5L', 'FAC1407/5L', 'FAC1408/5L', 'FAC1409/5L',\n",
        "        'FACL101/M', 'FACL102/M'\n",
        "    }\n",
        "    exclusion_skus_upper = {sku.upper() for sku in exclusion_skus}\n",
        "    result_df['5LL Pick Rule'] = result_df.apply(lambda row: \"EXCL\" if str(row.get('SKU Code', '')).strip().upper() in exclusion_skus_upper else \"PFS\", axis=1)\n",
        "    return result_df\n",
        "\n",
        "print(\"\\nSTEP 8: Calculate 5LL Pick Rule\")\n",
        "if order_data is not None:\n",
        "    order_data = calculate_5LL_pick_rule(order_data)\n",
        "    preview_data(order_data, \"Order Data with 5LL Pick Rule\")\n",
        "else:\n",
        "    order_data = None"
      ],
      "metadata": {
        "id": "PUkj0vmtdhiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply All Calculations and Save Intermediate Data"
      ],
      "metadata": {
        "id": "cz-GcrmvjGYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSTEP 9: Apply All Calculations and Save Intermediate Data\")\n",
        "if order_data is not None:\n",
        "    final_output = order_data.copy()\n",
        "    try:\n",
        "        with pd.ExcelWriter('Intermediate_Data.xlsx', engine='openpyxl') as writer:\n",
        "            inventory_data.to_excel(writer, sheet_name='Inventory_Data', index=False)\n",
        "            order_data.to_excel(writer, sheet_name='Order_Data', index=False)\n",
        "            final_output.to_excel(writer, sheet_name='Final_Results', index=False)\n",
        "        print(\"Intermediate data saved successfully as Intermediate_Data.xlsx\")\n",
        "        preview_data(final_output, \"Final Output Before Production Updates\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving intermediate data: {str(e)}\")\n",
        "else:\n",
        "    final_output = None"
      ],
      "metadata": {
        "id": "CIJh-Q5ddhlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Production Status Update Processing with Nested Loop"
      ],
      "metadata": {
        "id": "n2k74DD0jKRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_production_status_updates_with_classification():\n",
        "    global inventory_data, order_data, final_output\n",
        "\n",
        "    if final_output is None:\n",
        "        print(\"No final output data to process. Exiting.\")\n",
        "        return None, None\n",
        "\n",
        "    processed_repack = 0\n",
        "    processed_pick_stock = 0\n",
        "    skipped_complete = 0\n",
        "    skipped_plan = 0\n",
        "    skipped_raw_material = 0\n",
        "    skipped_other = 0\n",
        "    errors = 0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STARTING PRODUCTION STATUS PROCESSING WITH NESTED CLASSIFICATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    final_output_updated = final_output.copy()\n",
        "    order_data_updated = order_data.copy()\n",
        "\n",
        "    # Function to classify production status\n",
        "    def classify_production_status(row):\n",
        "        item = str(row.get('SKU Code', '')).strip()\n",
        "        order_type = str(row.get('Order Type', '')).strip().upper()\n",
        "        qty_outstanding = float(row.get('Qty Outstanding', 0))\n",
        "        available_caps = float(row.get('AVAILABLE CAPS', 0))\n",
        "        soh_new_lang_stock = float(row.get('SOH NEW LANG STOCK', 0))\n",
        "        pick_rule_5LL = str(row.get('5LL Pick Rule', '')).strip().upper()\n",
        "\n",
        "        if item and item[0].upper() == \"B\":\n",
        "            return \"Raw Material\"\n",
        "        elif not item or item.upper() == 'NAN':\n",
        "            return \"\"\n",
        "        elif qty_outstanding <= 0:\n",
        "            return \"COMPLETE\"\n",
        "        elif len(item) >= 2 and item[-2:].upper() == \"1L\":\n",
        "            return \"Repack\"\n",
        "        elif len(item) > 0 and item[-1].upper() in [\"C\", \"E\", \"F\", \"M\"]:\n",
        "            return \"Repack\"\n",
        "        elif order_type == \"ND\" and pick_rule_5LL == \"PFS\":\n",
        "            return \"Pick From Stock\"\n",
        "        elif order_type == \"TRUCK\" and pick_rule_5LL == \"PFS\":\n",
        "            return \"Pick From Stock\"\n",
        "        elif len(item) >= 3 and item[:3].upper() == \"FAC\" and qty_outstanding >= 20 and order_type == \"AIR\":\n",
        "            return \"PLAN\"\n",
        "        elif soh_new_lang_stock > 0 and qty_outstanding < (soh_new_lang_stock * 0.5):\n",
        "            return \"Pick From Stock\"\n",
        "        elif qty_outstanding < 12 and available_caps > 0 and qty_outstanding < (available_caps / 10):\n",
        "            return \"Repack\"\n",
        "        else:\n",
        "            return \"PLAN\"\n",
        "\n",
        "    for index, row in final_output_updated.iterrows():\n",
        "        try:\n",
        "            sku = row['SKU Code']\n",
        "            order_num = row['Order Number']\n",
        "            original_qty = float(row['Original Order Quantity'])  # Ensure numeric\n",
        "\n",
        "            # Dynamically classify status for the current row within the loop\n",
        "            status = classify_production_status(row)\n",
        "            final_output_updated.at[index, 'New Production Status'] = status\n",
        "            print(f\"\\nRow {index + 1}: SKU {sku}, Order {order_num}, Qty {original_qty}, Classified Status: '{status}'\")\n",
        "\n",
        "            available_caps_before = float(row['AVAILABLE CAPS'])\n",
        "            soh_stock_before = float(row['SOH NEW LANG STOCK'])\n",
        "\n",
        "            if status.lower() == 'repack':\n",
        "                print(f\"  -> REPACK: Reducing AVAILABLE CAPS by {original_qty}\")\n",
        "                print(f\"    Before: AVAILABLE CAPS = {available_caps_before}\")\n",
        "                new_available_caps = max(0, available_caps_before - original_qty)\n",
        "                final_output_updated.at[index, 'AVAILABLE CAPS'] = new_available_caps\n",
        "                print(f\"    Calculated new_available_caps: {new_available_caps}\")\n",
        "                print(f\"    After (in memory): AVAILABLE CAPS = {final_output_updated.at[index, 'AVAILABLE CAPS']}\")\n",
        "                order_mask = (order_data_updated['SKU Code'] == sku) & (order_data_updated['Order Number'] == order_num)\n",
        "                if order_mask.any():\n",
        "                    current_order_qty = float(order_data_updated.loc[order_mask, 'Order Quantity'].iloc[0])\n",
        "                    new_order_qty = max(0, current_order_qty - original_qty)\n",
        "                    order_data_updated.loc[order_mask, 'Order Quantity'] = new_order_qty\n",
        "                    print(f\"    Order data updated: {current_order_qty} -> {new_order_qty}\")\n",
        "                print(f\"    After: AVAILABLE CAPS = {new_available_caps}\")\n",
        "                processed_repack += 1\n",
        "\n",
        "            elif status.lower() == 'pick from stock':\n",
        "                print(f\"  -> PICK FROM STOCK: Reducing SOH NEW LANG STOCK by {original_qty}\")\n",
        "                print(f\"    Before: SOH NEW LANG STOCK = {soh_stock_before}\")\n",
        "                print(f\"    Original Qty from row: {float(row['Original Order Quantity'])}\")  # Verify original_qty\n",
        "                new_soh_stock = max(0, soh_stock_before - original_qty)\n",
        "                print(f\"    Calculated new_soh_stock: {new_soh_stock}\")  # Verify calculation\n",
        "                final_output_updated.at[index, 'SOH NEW LANG STOCK'] = new_soh_stock\n",
        "                print(f\"    After (in memory): SOH NEW LANG STOCK = {final_output_updated.at[index, 'SOH NEW LANG STOCK']}\")\n",
        "                order_mask = (order_data_updated['SKU Code'] == sku) & (order_data_updated['Order Number'] == order_num)\n",
        "                if order_mask.any():\n",
        "                    current_order_qty = float(order_data_updated.loc[order_mask, 'Order Quantity'].iloc[0])\n",
        "                    new_order_qty = max(0, current_order_qty - original_qty)\n",
        "                    order_data_updated.loc[order_mask, 'Order Quantity'] = new_order_qty\n",
        "                    print(f\"    Order data updated: {current_order_qty} -> {new_order_qty}\")\n",
        "                print(f\"    After: SOH NEW LANG STOCK = {new_soh_stock}\")\n",
        "                processed_pick_stock += 1\n",
        "\n",
        "            elif status.lower() == 'complete':\n",
        "                print(f\"  -> COMPLETE: No changes required\")\n",
        "                skipped_complete += 1\n",
        "\n",
        "            elif status.lower() == 'plan':\n",
        "                print(f\"  -> PLAN: No changes required\")\n",
        "                skipped_plan += 1\n",
        "\n",
        "            elif status.lower() == 'raw material':\n",
        "                print(f\"  -> RAW MATERIAL: No changes required\")\n",
        "                skipped_raw_material += 1\n",
        "\n",
        "            else:\n",
        "                print(f\"  -> UNKNOWN STATUS '{status}': No changes made\")\n",
        "                skipped_other += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  -> ERROR processing row {index + 1}: {str(e)}\")\n",
        "            errors += 1\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PROCESSING SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total rows processed: {len(final_output_updated)}\")\n",
        "    print(f\"REPACK items processed: {processed_repack}\")\n",
        "    print(f\"PICK FROM STOCK items processed: {processed_pick_stock}\")\n",
        "    print(f\"COMPLETE items skipped: {skipped_complete}\")\n",
        "    print(f\"PLAN items skipped: {skipped_plan}\")\n",
        "    print(f\"RAW MATERIAL items skipped: {skipped_raw_material}\")\n",
        "    print(f\"Other statuses skipped: {skipped_other}\")\n",
        "    print(f\"Errors encountered: {errors}\")\n",
        "\n",
        "    return final_output_updated, order_data_updated\n",
        "\n",
        "print(\"\\nSTEP 10: Processing Production Status Updates with Nested Classification\")\n",
        "updated_final_output, updated_order_data = process_production_status_updates_with_classification()"
      ],
      "metadata": {
        "id": "YOmhskEZdhrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual change for FAC1240/1L\n"
      ],
      "metadata": {
        "id": "yKc4H9JPZdf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Override: Change FAC1240/1L from \"Repack\" to \"Pick from stock\"\n",
        "print(\"\\nSTEP 12: Manual Production Status Override for FAC1240/1L\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if updated_final_output is not None:\n",
        "\n",
        "    target_sku = \"FAC1240/1L\"\n",
        "    mask = updated_final_output['SKU Code'].astype(str).str.strip().str.upper() == target_sku.upper()\n",
        "\n",
        "    if mask.any():\n",
        "        matching_rows = updated_final_output[mask]\n",
        "        print(f\"\\nFound {len(matching_rows)} row(s) with SKU Code '{target_sku}':\")\n",
        "\n",
        "        changes_made = 0\n",
        "        for idx in matching_rows.index:\n",
        "            current_status = str(updated_final_output.at[idx, 'New Production Status']).strip()\n",
        "            available_stock = float(updated_final_output.at[idx, 'SOH NEW LANG STOCK'])\n",
        "            order_num = updated_final_output.at[idx, 'Order Number']\n",
        "            original_qty = float(updated_final_output.at[idx, 'Original Order Quantity'])\n",
        "\n",
        "            print(f\"\\nRow {idx + 1} (Order: {order_num}):\")\n",
        "            print(f\"  Current Status: '{current_status}'\")\n",
        "            print(f\"  SOH NEW LANG STOCK: {available_stock}\")\n",
        "            print(f\"  Original Order Quantity: {original_qty}\")\n",
        "\n",
        "\n",
        "            if current_status.lower() == \"repack\" and available_stock > 0:\n",
        "                print(f\"  -> Changing status from 'Repack' to 'Pick from stock'\")\n",
        "                updated_final_output.at[idx, 'New Production Status'] = \"Pick from stock\"\n",
        "                changes_made += 1\n",
        "                print(f\"  ✓ Status updated successfully!\")\n",
        "            elif available_stock <= 0:\n",
        "                print(f\"  -> Skipping: Available stock is {available_stock} (must be > 0)\")\n",
        "            else:\n",
        "                print(f\"  -> Skipping: Current status is '{current_status}', not 'Repack'\")\n",
        "\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"Summary: {changes_made} row(s) updated for FAC1240/1L\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nAll rows for FAC1240/1L:\")\n",
        "        display_cols = ['Order Number', 'SKU Code', 'Original Order Quantity',\n",
        "                       'SOH NEW LANG STOCK', 'AVAILABLE CAPS', 'New Production Status']\n",
        "        available_cols = [col for col in display_cols if col in updated_final_output.columns]\n",
        "        print(updated_final_output[mask][available_cols].to_string(index=False))\n",
        "    else:\n",
        "        print(f\"\\nNo rows found with SKU Code '{target_sku}'\")\n",
        "        print(\"\\nNote: Make sure the data has been processed in previous steps.\")\n",
        "        print(\"If you're looking for a different SKU variant, please check the spelling.\")\n",
        "else:\n",
        "    print(\"ERROR: No updated_final_output data available.\")\n",
        "    print(\"Please run Steps 1-10 first to generate the output data.\")"
      ],
      "metadata": {
        "id": "mlpP4JpEYrR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Save and Download Final Output\n"
      ],
      "metadata": {
        "id": "uayVk_CWja84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSTEP 11: Saving and Downloading Final Output\")\n",
        "if updated_final_output is not None and updated_order_data is not None:\n",
        "    filename = 'Final_Production_Status_Results_Updated.xlsx'\n",
        "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "        updated_final_output.to_excel(writer, sheet_name='Final_Results', index=False)\n",
        "        updated_order_data.to_excel(writer, sheet_name='Updated_Orders', index=False)\n",
        "        if inventory_data is not None:\n",
        "            inventory_data.to_excel(writer, sheet_name='Inventory_Data', index=False)\n",
        "    print(f\"\\nSaving and downloading {filename}...\")\n",
        "    files.download(filename)\n",
        "    print(f\"Download initiated for {filename}\")\n",
        "    preview_data(updated_final_output, \"Updated Final Output\")\n",
        "else:\n",
        "    print(\"No data to save or download. Processing failed.\")"
      ],
      "metadata": {
        "id": "nsPatYUxdhtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhNwgEVaql0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}