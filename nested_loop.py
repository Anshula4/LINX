# -*- coding: utf-8 -*-
"""Nested loop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cex1HmbhbC1AHG6saL7bFJji_zUqHx4l

Install and Import Libraries
"""

# Install required packages
!pip install pandas openpyxl xlsxwriter -q

# Import necessary libraries
import pandas as pd
import numpy as np
from google.colab import files
import io
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

"""Define Helper Functions"""

# Function to upload and read an Excel file
def upload_excel_file(file_type):
    print(f"\nPlease upload your {file_type} Excel file:")
    uploaded = files.upload()
    if uploaded:
        filename = list(uploaded.keys())[0]
        try:
            df = pd.read_excel(io.BytesIO(uploaded[filename]))
            return df, filename
        except Exception as e:
            print(f"Error reading file: {str(e)}")
            return None, None

# Function to preview dataframe
def preview_data(df, title, max_rows=3):
    if df is not None:
        print(f"\n{'='*50}")
        print(f"{title} Preview")
        print(f"{'='*50}")
        print(f"Shape: {df.shape[0]} rows × {df.shape[1]} columns")
        print(f"\nFirst {max_rows} rows:")
        print(df.head(max_rows).to_string())

# Function to save and download DataFrame
def save_and_download_file(df, filename):
    try:
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Sheet1', index=False)
        print(f"\nSaving and downloading {filename}...")
        files.download(filename)
        print(f"Download initiated for {filename}")
        return True
    except Exception as e:
        print(f"Error saving/downloading file: {str(e)}")
        return False

"""Create Language Lookup Table"""

def create_language_lookup():
    lookup_data = [
        ['AE', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['AO', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['AR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['AT', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['AU', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['AZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['BA', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],
        ['BD', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['BE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['BG', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],
        ['BO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['BR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['BW', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['BY', 'English-Russia', 'SDWN EngRus'],
        ['CA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['CH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['CI', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['CL', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['CM', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['CN', 'English-Chinese', 'SDWN EnglishChinese'],
        ['CO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['CR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['CX', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],
        ['CY', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],
        ['CZ', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],
        ['DE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['DK', 'EN-DA-SV-NN', 'SDWN ENDASVNN'],
        ['DO', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['DU', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['DX', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['DZ', 'ENGLISH-ARABIC', 'SDWN EngArabic Codal'],
        ['EC', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['EE', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],
        ['EG', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['ES', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['FI', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],
        ['FR', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['GB', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['GE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['GH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['GP', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['GR', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],
        ['HK', 'English-Chinese', 'SDWN EnglishChinese'],
        ['HR', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],
        ['HU', 'English-Hungary (Printec)', 'SDWN EngHungary'],
        ['ID', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['IE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['IL', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['IN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['IQ', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['IR', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['IT', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],
        ['JO', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['JP', 'English-Japanese', 'SDWN EngJapan'],
        ['KE', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['KG', 'English-Russia', 'SDWN EngRus'],
        ['KR', 'English-Korean', 'SDWN EngKorean'],
        ['KW', 'English-Arabic', 'SDWN EngArabic'],
        ['KZ', 'English-Russia', 'SDWN EngRus'],
        ['LB', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['LK', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['LT', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],
        ['LV', 'EN-FI-ET-LT', 'SDWN ENFIETLT'],
        ['LY', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['MA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['MC', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['MD', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['MU', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['MX', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['MY', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['NC', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['NG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['NL', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['NO', 'EN-DA-SV-NL', 'SDWN ENDASVNL'],
        ['NP', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['NZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['OM', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['PE', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['PH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['PK', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['PL', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],
        ['PR', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['PT', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['PY', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['QA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['RO', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],
        ['RS', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],
        ['RU', 'English-Russia', 'SDWN EngRus'],
        ['SA', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['SD', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['SE', 'EN-DA-SV-NL', 'SDWN ENDASVNL'],
        ['SG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['SI', 'EN-HR-BG-SL', 'SDWN ENHRBGSL'],
        ['SK', 'EN-PL-CS-RO', 'SDWN ENPLCSRO'],
        ['SN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['SV', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['SY', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['TG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['TH', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['TJ', 'English-Russia', 'SDWN EngRus'],
        ['TN', 'ENGLISH-ARABIC', 'SDWN EngArabic'],
        ['TR', 'EN-TR-EL-IT', 'SDWN ENTRELIT'],
        ['TT', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['TW', 'English-ChineseT', 'SDWN EnglishChinaT'],
        ['UA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['UG', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['US', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['UZ', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['VE', 'EN-FR-ES-PT(BR)', 'SDWN ENFRESPTBR'],
        ['VN', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['XS', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['XX', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['ZA', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['ZM', 'EN-FR-DE-NL', 'SDWN ENFRDENL'],
        ['ZW', 'EN-FR-DE-NL', 'SDWN ENFRDENL']
    ]
    lang_lookup_df = pd.DataFrame(lookup_data, columns=['COUNTRY_CODE', 'NEW_LANG', 'SDWN'])
    return lang_lookup_df

language_lookup = create_language_lookup()
print("lang_lookup_df sample:", language_lookup.head().to_string())

"""Upload and Process SOH Bottles Data"""

print("\nSTEP 1: Upload SOH Bottles Excel File")
soh_data, soh_filename = upload_excel_file("SOH Bottles Sheet")
if soh_data is not None:
    item_col = next((col for col in soh_data.columns if 'item' in str(col).lower()), None)
    if item_col:
        soh_data = soh_data[soh_data[item_col].notna() & (soh_data[item_col].astype(str).str.strip() != '')]
    preview_data(soh_data, "SOH Bottles Data")

"""Upload and Process Export Sheet"""

print("\nSTEP 2: Upload and Convert Export Sheet to Order Format")
export_data, export_filename = upload_excel_file("Export Sheet")
if export_data is not None:
    print(f"Initial data shape: {export_data.shape[0]} rows × {export_data.shape[1]} columns")

    # Filter out Released status
    status_column = next((col for col in export_data.columns if 'status' in str(col).lower()), export_data.columns[17] if export_data.shape[1] >= 18 else None)
    if status_column:
        print(f"\nFiltering out orders with Status = 'Released' from column: '{status_column}'")
        before_filter = len(export_data)
        export_data = export_data[~export_data[status_column].astype(str).str.upper().str.strip().eq('RELEASED')]
        print(f"Removed {before_filter - len(export_data)} orders with 'Released' status")
    else:
        print("WARNING: Status column not found")

    # Filter out batch-assigned orders
    batch_columns = [col for col in export_data.columns if any(kw in str(col).lower() for kw in ['batch', 'lot', 'production order', 'work order'])]
    print(f"\nFound potential batch columns: {batch_columns}")
    if batch_columns:
        before_batch_filter = len(export_data)
        batch_filter_mask = pd.Series(False, index=export_data.index)
        for batch_col in batch_columns:
            has_batch = (
                export_data[batch_col].notna() &
                (export_data[batch_col].astype(str).str.strip() != '') &
                (export_data[batch_col].astype(str).str.strip().str.upper() != 'NAN')
            )
            batch_filter_mask |= has_batch
            print(f"  {batch_col}: {has_batch.sum()} orders have batch numbers assigned")
        export_data = export_data[~batch_filter_mask]
        print(f"Removed {before_batch_filter - len(export_data)} orders with batch numbers assigned")
    else:
        print("No batch-related columns found")

    # Filter non-empty sales orders
    sales_col = next((col for col in export_data.columns if 'sales order' in str(col).lower()), None)
    if sales_col:
        before_sales_filter = len(export_data)
        export_data = export_data[export_data[sales_col].notna() & (export_data[sales_col].astype(str).str.strip() != '')]
        print(f"Removed {before_sales_filter - len(export_data)} empty sales orders")
    print(f"\nFinal filtered data shape: {export_data.shape[0]} rows × {export_data.shape[1]} columns")

    # Convert to order format
    order_data = pd.DataFrame()
    column_mappings = {
        'Order Number': ['sales order'],
        'Customer ID': ['ship to country'],
        'SKU Code': ['item'],
        'Original Order Quantity': ['quantity'],
        'Reserved Quantity': ['reserved quantity'],
        'Order Date (dd/mm/yyyy)': ['upload date', 'batch start date', 'order date', 'date'],
        'Requested Delivery Date (dd/mm/yyyy)': ['scheduled ship date', 'due date', 'schedule ship date'],
        'Priority': ['language'],
        'Order Type': ['delivery method'],
        'Agent Name': ['linx agent', 'on hold', 'agent']
    }
    for target_col, search_terms in column_mappings.items():
        source_col = next((col for col in export_data.columns if any(term.lower() in str(col).lower() for term in search_terms)), None)
        if source_col:
            order_data[target_col] = export_data[source_col]
            print(f"Mapped '{target_col}' to source column: '{source_col}'")
        else:
            if target_col == 'Agent Name':
                order_data[target_col] = 'Linx Agent'
            elif target_col == 'Order Date (dd/mm/yyyy)':
                order_data[target_col] = datetime.now().strftime('%d/%m/%Y')
            elif target_col == 'Reserved Quantity':
                order_data[target_col] = 0
                print(f"WARNING: No 'Reserved Quantity' column found. Defaulting to 0.")
            else:
                order_data[target_col] = ''

    # Set Order Quantity and add other columns
    order_data['Original Order Quantity'] = pd.to_numeric(order_data['Original Order Quantity'], errors='coerce').fillna(0)
    order_data['Reserved Quantity'] = pd.to_numeric(order_data['Reserved Quantity'], errors='coerce').fillna(0)
    order_data['Order Quantity'] = order_data['Reserved Quantity']
    order_data['Location ID'] = 'WH_Default'

    # Split Order Number into Order Number and Line Number
    if 'Order Number' in order_data.columns:
        order_line_data = order_data['Order Number'].apply(lambda x: ('LI' + str(x).split('/')[0], str(x).split('/')[1]) if '/' in str(x) else ('LI' + str(x), '1'))
        order_data['Order Number'] = [x[0] for x in order_line_data]
        order_data['Line Number'] = [x[1] for x in order_line_data]
    else:
        order_data['Line Number'] = range(1, len(export_data) + 1)

    # Format dates
    for date_col in ['Order Date (dd/mm/yyyy)', 'Requested Delivery Date (dd/mm/yyyy)']:
        if date_col in order_data.columns:
            order_data[date_col] = pd.to_datetime(order_data[date_col], errors='coerce').dt.strftime('%d/%m/%Y')

    # Ensure required columns
    required_columns = [
        'Order Number', 'Line Number', 'Location ID', 'Customer ID', 'SKU Code',
        'Original Order Quantity', 'Order Quantity', 'Order Date (dd/mm/yyyy)',
        'Requested Delivery Date (dd/mm/yyyy)', 'Priority', 'Order Type', 'Agent Name'
    ]
    for col in required_columns:
        if col not in order_data.columns:
            order_data[col] = '1' if col == 'Line Number' else 'WH_Default' if col == 'Location ID' else 0 if col == 'Order Quantity' else ''
    order_data = order_data[required_columns]

    print("order_data Customer IDs sample:", order_data['Customer ID'].head(10).to_string())
    preview_data(order_data, "Converted Order Data (Open Orders Only)")
else:
    order_data = None

"""Convert SOH Bottles to Inventory Format"""

print("\nSTEP 3: Convert SOH Bottles Sheet to Inventory Format")
if soh_data is not None:
    inventory_data = pd.DataFrame()
    soh_mappings = {
        'SKU Code': ['item', 'sku'],
        'On Hand Inventory': ['available to reserve', 'available'],
        'Reordered Quantity': ['total quantity', 'onhand', 'stock', 'quantity'],
        'Locator': ['locator']
    }
    for target_col, search_terms in soh_mappings.items():
        source_col = next((col for col in soh_data.columns if any(term.lower() in str(col).lower() for term in search_terms)), None)
        if source_col:
            inventory_data[target_col] = soh_data[source_col]
        else:
            inventory_data[target_col] = 0 if 'quantity' in target_col.lower() or 'inventory' in target_col.lower() else ''

    # Exclude specific locators and add Location ID
    if 'Locator' in inventory_data.columns:
        exclude_mask = inventory_data['Locator'].astype(str).str.strip().str.upper() == '8900MAIN'
        inventory_data = inventory_data[~exclude_mask].copy()
        inventory_data['Location ID'] = inventory_data['Locator']
    else:
        inventory_data['Location ID'] = ''

    # Add timestamp and aggregate
    current_time = datetime.now().strftime('%d-%m-%Y %H:%M:%S')
    inventory_data['Date and Time (DD-MM-YYYY HH:MM:SS)'] = current_time
    inventory_data['On Hand Inventory'] = pd.to_numeric(inventory_data['On Hand Inventory'], errors='coerce').fillna(0)
    inventory_data['Reordered Quantity'] = pd.to_numeric(inventory_data['Reordered Quantity'], errors='coerce').fillna(0)
    inventory_data = inventory_data.groupby(['SKU Code', 'Location ID', 'Date and Time (DD-MM-YYYY HH:MM:SS)'], as_index=False).agg({
        'On Hand Inventory': 'sum',
        'Reordered Quantity': 'sum'
    })

    # Create copy with locator for later use
    inventory_data_with_locator = inventory_data.copy()
    inventory_data_with_locator['Locator'] = inventory_data_with_locator['Location ID']

    # Select required columns
    required_inventory_columns = [
        'Location ID', 'SKU Code', 'On Hand Inventory', 'Reordered Quantity',
        'Date and Time (DD-MM-YYYY HH:MM:SS)'
    ]
    inventory_data = inventory_data[required_inventory_columns]

    preview_data(inventory_data, "Converted Inventory Data")
else:
    inventory_data = None
    inventory_data_with_locator = None

"""Calculate New Lang Label and Stock"""

def calculate_new_lang_label_and_stock(order_df, inventory_with_locator_df, lang_lookup_df):
    result_df = order_df.copy()
    if inventory_with_locator_df is None or lang_lookup_df is None:
        print("WARNING: inventory_with_locator_df or lang_lookup_df is None. Setting SOH NEW LANG STOCK to 0.")
        result_df['ITEM New LANG LABEL'] = result_df['SKU Code']
        result_df['SOH NEW LANG STOCK'] = 0
        return result_df

    def calculate_lang_info_for_item(row):
        sku_code = str(row.get('SKU Code', '')).strip()
        country = str(row.get('Customer ID', '')).strip().upper()
        print(f"Processing row: SKU={sku_code}, Raw Customer ID={row.get('Customer ID', '')}, Processed Country={country}")
        new_lang_label = sku_code
        soh_new_lang_stock = 0

        if pd.isna(sku_code) or sku_code == '' or pd.isna(country) or country == '':
            print(f"Skipping row: SKU={sku_code}, Country={country} (empty or invalid)")
            return new_lang_label, soh_new_lang_stock

        country_match = lang_lookup_df[lang_lookup_df['COUNTRY_CODE'].str.upper() == country]
        if len(country_match) == 0:
            print(f"No country match found for Customer ID: {country}, using default EN-FR-DE-NL")
            new_lang = 'EN-FR-DE-NL'  # Default language as fallback
        else:
            new_lang = country_match.iloc[0]['NEW_LANG']
        new_lang_label = f"{sku_code}{new_lang}"
        search_key = f"{sku_code}{new_lang}"

        print(f"Searching for SKU={sku_code}, Country={country}, Search Key={search_key}")

        matching_soh = inventory_with_locator_df[
            (inventory_with_locator_df['SKU Code'].astype(str).str.strip() +
             inventory_with_locator_df['Locator'].astype(str).str.strip()).str.upper() == search_key.upper()
        ]
        if len(matching_soh) > 0:
            soh_new_lang_stock = pd.to_numeric(matching_soh['On Hand Inventory'], errors='coerce').fillna(0).sum()
            print(f"Match found (SKU+Locator): {search_key}, Stock={soh_new_lang_stock}")
        else:
            matching_soh_direct = inventory_with_locator_df[
                inventory_with_locator_df['SKU Code'].astype(str).str.strip().str.upper() == search_key.upper()
            ]
            if len(matching_soh_direct) > 0:
                soh_new_lang_stock = pd.to_numeric(matching_soh_direct['On Hand Inventory'], errors='coerce').fillna(0).sum()
                print(f"Match found (SKU direct): {search_key}, Stock={soh_new_lang_stock}")
            else:
                base_sku_match = inventory_with_locator_df[
                    inventory_with_locator_df['SKU Code'].astype(str).str.strip().str.upper() == sku_code.upper()
                ]
                if len(base_sku_match) > 0:
                    soh_new_lang_stock = pd.to_numeric(base_sku_match['On Hand Inventory'], errors='coerce').fillna(0).sum()
                    print(f"Using base SKU {sku_code}, Stock={soh_new_lang_stock}")
                else:
                    print(f"No match found for {search_key} or base SKU {sku_code}")

        return new_lang_label, soh_new_lang_stock

    lang_results = result_df.apply(calculate_lang_info_for_item, axis=1, result_type='expand')
    result_df['ITEM New LANG LABEL'] = lang_results[0]
    result_df['SOH NEW LANG STOCK'] = lang_results[1]
    return result_df

print("\nSTEP 4: Calculate New Lang Label and Stock")
if order_data is not None and inventory_data is not None and language_lookup is not None:
    order_data = calculate_new_lang_label_and_stock(order_data, inventory_data_with_locator, language_lookup)
    preview_data(order_data, "Order Data with New Lang Label and Stock")
else:
    order_data = None

"""Calculate Qty Outstanding"""

def calculate_qty_outstanding(order_df):
    result_df = order_df.copy()
    original_qty = pd.to_numeric(result_df['Original Order Quantity'], errors='coerce').fillna(0)
    reserved_qty = pd.to_numeric(result_df['Order Quantity'], errors='coerce').fillna(0)
    result_df['Qty Outstanding'] = (original_qty - reserved_qty).clip(lower=0)
    return result_df

print("\nSTEP 5: Calculate Qty Outstanding")
if order_data is not None:
    order_data = calculate_qty_outstanding(order_data)
    preview_data(order_data, "Order Data with Qty Outstanding")
else:
    order_data = None

"""Calculate Available CAPS"""

def calculate_available_caps(order_df, inventory_df):
    result_df = order_df.copy()
    if inventory_df is None:
        result_df['AVAILABLE CAPS'] = 0
        return result_df

    def calculate_caps_for_item(item_code):
        if pd.isna(item_code) or str(item_code).strip() == '':
            return 0
        item_str = str(item_code).strip()
        if len(item_str) >= 7:
            mid_substring = item_str[2:7]
            search_pattern = f"AS{mid_substring}"
            matching_items = inventory_df[
                inventory_df['SKU Code'].astype(str).str.contains(search_pattern, case=False, na=False, regex=False)
            ]
            if len(matching_items) > 0:
                return pd.to_numeric(matching_items['On Hand Inventory'], errors='coerce').fillna(0).sum()
        return 0

    result_df['AVAILABLE CAPS'] = result_df['SKU Code'].apply(calculate_caps_for_item)
    return result_df

print("\nSTEP 6: Calculate Available CAPS")
if order_data is not None and inventory_data is not None:
    order_data = calculate_available_caps(order_data, inventory_data)
    preview_data(order_data, "Order Data with Available CAPS")
else:
    order_data = None

"""Calculate 5 LANG Box Stock Item"""

def calculate_5_lang_box_stock(order_df, inventory_df):
    result_df = order_df.copy()
    if inventory_df is None:
        result_df['5 LANG Box Stock item (Y/N)'] = 'N'
        return result_df

    def calculate_lang_box_for_item(sku_code):
        if pd.isna(sku_code) or str(sku_code).strip() == '':
            return 'N'
        sku_str = str(sku_code).strip().upper()
        matching_rows = inventory_df[
            inventory_df['SKU Code'].astype(str).str.strip().str.upper() == sku_str
        ]
        if len(matching_rows) > 0:
            soh_stock = pd.to_numeric(matching_rows['On Hand Inventory'], errors='coerce').fillna(0).sum()
            return 'Y' if soh_stock > 0 else 'N'
        return 'N'

    result_df['5 LANG Box Stock item (Y/N)'] = result_df['SKU Code'].apply(calculate_lang_box_for_item)
    return result_df

print("\nSTEP 7: Calculate 5 LANG Box Stock Item (Y/N)")
if order_data is not None and inventory_data is not None:
    order_data = calculate_5_lang_box_stock(order_data, inventory_data)
    preview_data(order_data, "Order Data with 5 LANG Box Stock")
else:
    order_data = None

"""Calculate 5LL Pick Rule"""

def calculate_5LL_pick_rule(order_df):
    result_df = order_df.copy()
    exclusion_skus = {
        'FAC1248/5L', 'FAC1058/5L', 'FAC1079/5L', 'FAC1039/5L', 'FAC1405/5L',
        'FAC1404/5L', 'FAC1406/5L', 'FAC1407/5L', 'FAC1408/5L', 'FAC1409/5L',
        'FACL101/M', 'FACL102/M'
    }
    exclusion_skus_upper = {sku.upper() for sku in exclusion_skus}
    result_df['5LL Pick Rule'] = result_df.apply(lambda row: "EXCL" if str(row.get('SKU Code', '')).strip().upper() in exclusion_skus_upper else "PFS", axis=1)
    return result_df

print("\nSTEP 8: Calculate 5LL Pick Rule")
if order_data is not None:
    order_data = calculate_5LL_pick_rule(order_data)
    preview_data(order_data, "Order Data with 5LL Pick Rule")
else:
    order_data = None

"""Apply All Calculations and Save Intermediate Data"""

print("\nSTEP 9: Apply All Calculations and Save Intermediate Data")
if order_data is not None:
    final_output = order_data.copy()
    try:
        with pd.ExcelWriter('Intermediate_Data.xlsx', engine='openpyxl') as writer:
            inventory_data.to_excel(writer, sheet_name='Inventory_Data', index=False)
            order_data.to_excel(writer, sheet_name='Order_Data', index=False)
            final_output.to_excel(writer, sheet_name='Final_Results', index=False)
        print("Intermediate data saved successfully as Intermediate_Data.xlsx")
        preview_data(final_output, "Final Output Before Production Updates")
    except Exception as e:
        print(f"Error saving intermediate data: {str(e)}")
else:
    final_output = None

"""Production Status Update Processing with Nested Loop"""

def process_production_status_updates_with_classification():
    global inventory_data, order_data, final_output

    if final_output is None:
        print("No final output data to process. Exiting.")
        return None, None

    processed_repack = 0
    processed_pick_stock = 0
    skipped_complete = 0
    skipped_plan = 0
    skipped_raw_material = 0
    skipped_other = 0
    errors = 0

    print("\n" + "="*80)
    print("STARTING PRODUCTION STATUS PROCESSING WITH NESTED CLASSIFICATION")
    print("="*80)

    final_output_updated = final_output.copy()
    order_data_updated = order_data.copy()

    # Function to classify production status
    def classify_production_status(row):
        item = str(row.get('SKU Code', '')).strip()
        order_type = str(row.get('Order Type', '')).strip().upper()
        qty_outstanding = float(row.get('Qty Outstanding', 0))
        available_caps = float(row.get('AVAILABLE CAPS', 0))
        soh_new_lang_stock = float(row.get('SOH NEW LANG STOCK', 0))
        pick_rule_5LL = str(row.get('5LL Pick Rule', '')).strip().upper()

        if item and item[0].upper() == "B":
            return "Raw Material"
        elif not item or item.upper() == 'NAN':
            return ""
        elif qty_outstanding <= 0:
            return "COMPLETE"
        elif len(item) >= 2 and item[-2:].upper() == "1L":
            return "Repack"
        elif len(item) > 0 and item[-1].upper() in ["C", "E", "F", "M"]:
            return "Repack"
        elif order_type == "ND" and pick_rule_5LL == "PFS":
            return "Pick From Stock"
        elif order_type == "TRUCK" and pick_rule_5LL == "PFS":
            return "Pick From Stock"
        elif len(item) >= 3 and item[:3].upper() == "FAC" and qty_outstanding >= 20 and order_type == "AIR":
            return "PLAN"
        elif soh_new_lang_stock > 0 and qty_outstanding < (soh_new_lang_stock * 0.5):
            return "Pick From Stock"
        elif qty_outstanding < 12 and available_caps > 0 and qty_outstanding < (available_caps / 10):
            return "Repack"
        else:
            return "PLAN"

    for index, row in final_output_updated.iterrows():
        try:
            sku = row['SKU Code']
            order_num = row['Order Number']
            original_qty = float(row['Original Order Quantity'])  # Ensure numeric

            # Dynamically classify status for the current row within the loop
            status = classify_production_status(row)
            final_output_updated.at[index, 'New Production Status'] = status
            print(f"\nRow {index + 1}: SKU {sku}, Order {order_num}, Qty {original_qty}, Classified Status: '{status}'")

            available_caps_before = float(row['AVAILABLE CAPS'])
            soh_stock_before = float(row['SOH NEW LANG STOCK'])

            if status.lower() == 'repack':
                print(f"  -> REPACK: Reducing AVAILABLE CAPS by {original_qty}")
                print(f"    Before: AVAILABLE CAPS = {available_caps_before}")
                new_available_caps = max(0, available_caps_before - original_qty)
                final_output_updated.at[index, 'AVAILABLE CAPS'] = new_available_caps
                print(f"    Calculated new_available_caps: {new_available_caps}")
                print(f"    After (in memory): AVAILABLE CAPS = {final_output_updated.at[index, 'AVAILABLE CAPS']}")
                order_mask = (order_data_updated['SKU Code'] == sku) & (order_data_updated['Order Number'] == order_num)
                if order_mask.any():
                    current_order_qty = float(order_data_updated.loc[order_mask, 'Order Quantity'].iloc[0])
                    new_order_qty = max(0, current_order_qty - original_qty)
                    order_data_updated.loc[order_mask, 'Order Quantity'] = new_order_qty
                    print(f"    Order data updated: {current_order_qty} -> {new_order_qty}")
                print(f"    After: AVAILABLE CAPS = {new_available_caps}")
                processed_repack += 1

            elif status.lower() == 'pick from stock':
                print(f"  -> PICK FROM STOCK: Reducing SOH NEW LANG STOCK by {original_qty}")
                print(f"    Before: SOH NEW LANG STOCK = {soh_stock_before}")
                print(f"    Original Qty from row: {float(row['Original Order Quantity'])}")  # Verify original_qty
                new_soh_stock = max(0, soh_stock_before - original_qty)
                print(f"    Calculated new_soh_stock: {new_soh_stock}")  # Verify calculation
                final_output_updated.at[index, 'SOH NEW LANG STOCK'] = new_soh_stock
                print(f"    After (in memory): SOH NEW LANG STOCK = {final_output_updated.at[index, 'SOH NEW LANG STOCK']}")
                order_mask = (order_data_updated['SKU Code'] == sku) & (order_data_updated['Order Number'] == order_num)
                if order_mask.any():
                    current_order_qty = float(order_data_updated.loc[order_mask, 'Order Quantity'].iloc[0])
                    new_order_qty = max(0, current_order_qty - original_qty)
                    order_data_updated.loc[order_mask, 'Order Quantity'] = new_order_qty
                    print(f"    Order data updated: {current_order_qty} -> {new_order_qty}")
                print(f"    After: SOH NEW LANG STOCK = {new_soh_stock}")
                processed_pick_stock += 1

            elif status.lower() == 'complete':
                print(f"  -> COMPLETE: No changes required")
                skipped_complete += 1

            elif status.lower() == 'plan':
                print(f"  -> PLAN: No changes required")
                skipped_plan += 1

            elif status.lower() == 'raw material':
                print(f"  -> RAW MATERIAL: No changes required")
                skipped_raw_material += 1

            else:
                print(f"  -> UNKNOWN STATUS '{status}': No changes made")
                skipped_other += 1

        except Exception as e:
            print(f"  -> ERROR processing row {index + 1}: {str(e)}")
            errors += 1

    print("\n" + "="*80)
    print("PROCESSING SUMMARY")
    print("="*80)
    print(f"Total rows processed: {len(final_output_updated)}")
    print(f"REPACK items processed: {processed_repack}")
    print(f"PICK FROM STOCK items processed: {processed_pick_stock}")
    print(f"COMPLETE items skipped: {skipped_complete}")
    print(f"PLAN items skipped: {skipped_plan}")
    print(f"RAW MATERIAL items skipped: {skipped_raw_material}")
    print(f"Other statuses skipped: {skipped_other}")
    print(f"Errors encountered: {errors}")

    return final_output_updated, order_data_updated

print("\nSTEP 10: Processing Production Status Updates with Nested Classification")
updated_final_output, updated_order_data = process_production_status_updates_with_classification()

"""
Save and Download Final Output
"""

print("\nSTEP 11: Saving and Downloading Final Output")
if updated_final_output is not None and updated_order_data is not None:
    filename = 'Final_Production_Status_Results_Updated.xlsx'
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        updated_final_output.to_excel(writer, sheet_name='Final_Results', index=False)
        updated_order_data.to_excel(writer, sheet_name='Updated_Orders', index=False)
        if inventory_data is not None:
            inventory_data.to_excel(writer, sheet_name='Inventory_Data', index=False)
    print(f"\nSaving and downloading {filename}...")
    files.download(filename)
    print(f"Download initiated for {filename}")
    preview_data(updated_final_output, "Updated Final Output")
else:
    print("No data to save or download. Processing failed.")

